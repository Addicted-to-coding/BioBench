<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A collaboratively built large language model benchmark for bioinformatics reasoning </title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>A collaboratively built large language model benchmark for Bioinformatics reasoning</h1>
        <nav>
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#tasks">Tasks</a></li>
                <li><a href="#data">Data</a></li>
                <li><a href="#contribute">Contribute</a></li>
                <li><a href="#contributors">Contributors</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <section id="about">
        <h2>What is BioinfoBench</h2>
        <p>The BioinfoBench project is an ongoing open science effort to collaboratively curate tasks for evaluating Bioinformatics reasoning in English large language models (LLMs). 
            The benchmark currently consists of 700 tasks gathered from 10 contributors.</p>

    </section>

    <section id="tasks">
        <h2>Where do the tasks come from?</h2>
        <p>Notably, BioinfoBench tasks have been assembled through a unique crowd-sourcing effort within the Bioinformatics community. BioinfoBench consists of two datasets, the public set and the private set. The public set comes from questions sourced from bioinformatics textbooks.
            The private set is composed of real world exam questions manually prepared by faculty. BioinfoBench is ongoing and we are always looking to incorporate more tasks. See below for more information on how to get involved!
        </p>
    </section>

    <section id="data">
        <h2>Data</h2>
        <p>The public set currently consists of 700 questions, from introduction to bioinformatics, biostatistics and genetics textbooks. 
            The private set is under preparation. The public set will be made publically available once the paper is published.
            BioinfoBench provides a means of assessing the performance of different LLMs for bioinformatics tasks.
             As the bioinformatics community increasingly explores the potential applications and uses for LLMs, empirical assessments of LLM performance on domain-relevant tasks grow in importance. 
             BioinfoBench provides bioinformatics researchers with guidance on the types of tasks for which current LLMs/prompting methods are proficient, and the types where significant technical improvements are necessary.</p>
    </section>

    <section id="contribute">
        <h2>Contribute</h2>
        <p>If you have a task or dataset in mind, we ask that you first reach out to us (contact Varuni at vsarwal@g.ucla.edu) with a description of the task and the dataset.
             Task contributions undergo a review process for both correctness and ambiguity. 
            We will then work with you to incorporate the dataset into BioinfoBench. Datasets must contain atleaset 50 samples to be considered.
            Task contributors will be invited to co-author our paper.</p>
    </section>

    <section id="contributors">
        <h2>Contributors</h2>
        <p>The following individuals have contributed towards BioinfoLLMBench</p>
        <ul>
            <li>Serghei Mangul</li>
            <li>Wei Wang</li>
            <li>Eleazar Eskin</li>
            <li>Taras Oleksyk</li>
          </ul
    </section>

    <section id="contact">
        <h2>Contact</h2>
        <p>BioinfoBench is a large scale collaboration. For questions or concerns, please contact Varuni Sarwal (vsarwal@g.ucla.edu).</p>
    </section>
    <footer>
        <!-- <p>&copy; 2024 Hazy Research. All rights reserved.</p> -->
    </footer>
</body>
</html>
